## 1727. (M) Largest Submatrix With Rearrangements

### `solution.py`
A brute force solution that actually reorders the columns to search for the largest submatrix is obviously not feasible. Instead we need to devise a method that does so without modifying `matrix`. First off, we know that we need at least 2 pieces of information about the `1`s in the matrix. We need to know the length of a run of column-wise consecutive `1`s, as well as the position of that run within its column. Let's say we preprocess `matrix` into a 2D list of tuples that contain the length of a run of `1`s and the position of that run within its column. The resulting list contains the information we need in an explicit manner, but there is no intuitive way to use this information to compute the size of the largest submatrix. Instead, we can implicitly store the spatial information by storing the length of a run of `1`s that end at a square. For example if `matrix = [[0,0,1],[0,1,1],[1,1,1]]`, the preprocessed value of `matrix[1][2]` would be `2`. If we sort a row containing these values in descending order, we can see how we could compute the size of the largest submatrix that 'ends' at that row. Because `row[i]` is smaller than or equal to all items in `row[:i]`, the largest size matrix we can fit has the size `row[i] * (i + 1)`.  
We initialize a 2D list `runs` that will contain the preprocessed values described above. After `runs` is populated we iterate over each row. During each iteration we sort the row in descending order and iterate along the sorted row, updating the largest size `ret` if the size of the largest submatrix at the current position is determined to be larger. Once the entirety of `runs` has been examined we simply return `run`.  

#### Conclusion
The time complexity of this solution is $O(mn\log n)$ where $m$ is the number of rows and $n$ the number of columns of `matrix`, respectively. Preprocessing `matrix` takes $O(mn)$ time. We then iterate over the preprocessed values in `runs` row-by-row. For each row, we first sort it before scanning it for possible submatrix sizes, which takes $O(n\log n)$ time. The space complexity is $O(mn)$, as we store all preprocessed values in memory. This can be reduced down to $O(n)$ if each preprocessed row is computed on the fly.  
  

### `solution_2.py`
There is also a method that does away with the sorting step for each row, instead keeping it ordered by implicitly sorting the values. Returning to the discarded idea of explicitly storing the length and position information in tuples, we can modify this idea and instead store the length of runs of `1`s that end at the current row along with their column number in a list of tuples. We will keep track of this information in 2 lists; one for the previous row, and one for the current. If we *assume* that the previous row is already sorted with respect to the lengths, we can also guarantee that the current row is also sorted if we generate it using the previous row. We first examine all tuples in the previous row. If a run of `1`s can be extended in the current row we extend the length by `1` and add the new tuple to the current row. We then examine the current row in `matrix` and add new runs if they exist. When we extend the runs of the current row in the previous step, we also populate a list of booleans `seen` where `seen[i]` is `True` if the `i`th item in the current row of `matrix` was used to extend a run or `False` otherwise. Once these steps are complete we finally iterate over the current row's lengths and compute the largest submatrix size that we can fit.  

#### Conclusion
This solution has a time complexity of $O(mn)$ as the list of lengths is implicitly sorted. The space complexity is $O(n)$ since 3 lists of length $O(n)$ are kept in memory as we iterate over each row in `matrix`.  
  

