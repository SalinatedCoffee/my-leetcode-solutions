## 916. (M) Word Subsets

### `solution.py`
For a string `s` and list of strings `s_l`, `s` is called **universal** against `s_l` if the characters of `s` is a superset of `s_l[i]`, for all possible values of `i`. Given the lists of strings `words1` and `words2`, we are asked to return a list of strings in `words1` that are universal against `words2`.  
Because we are working with sets, we do not have to consider the order or appearance of each character. This greatly simplifies the problem since we only need to keep track of the set of characters and the frequency of each of them. For a word to be universal against a list of words, it needs to be a superset of each and every word in the list. Instead of checking the entire list from scratch every time we want to determine whether a word is universal, we can preprocess the list by generating the **smallest set** that is a superset of each and every word in the list. If a word is a superset of this set, we know that it is universal.  
We can represent a set of characters plus the multiplicity of each character by using a dictionary. Iterating over `words2`, we create a frequency set for each word and update the dictionary for the smallest set using its contents. Since the set needs to contain any string in `words2`, we need to update it accordingly. For example, if the current smallest superset is `{a: 1, b: 3}` and the current word is `{a: 3, b: 3}`, the value of `a` in the superset must be changed to `3` for it to contain the current word. Once the superset has been generated, we iterate over `words1` while comparing the frequency list of each word against the superset. If the current word is smaller than the superset it is impossible for it to be universal, and we move on to the next word. Otherwise, we add the word to the list of universal words `res`.  

#### Conclusion
This solution has a time complexity of $O(mk+nl)$, where $n$, $m$ are the lengths of `words1` and `words2`, and $l$, $k$ are the greatest length of the strings in `words1` and `words2`. When determining the smallest superset, we iterate over the entirety of `words2` and generate a frequency list for each word. Since generating a frequency list is a linear time operation that scales with the length of the string, this step will finish in $O(mk)$ time. During the counting step, all elements in `words1` are examined, with a frequency list being generated for each word much like the previous step. Comparing the generated list against the superset is a $O(1)$ operation since the size of the alphabet of the strings is constant(26, since they are comprised of lowercase English letters only). Thus, this step requires $O(nl)$ time to complete, bringing the overall time complexity to $O(mk+nl)$. The space complexity is $O(l+k)$, due to the superset `superset` and the frequency list for each string in `words1` during the counting step.  
  

