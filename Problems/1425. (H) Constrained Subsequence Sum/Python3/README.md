## 1425. (H) Constrained Subsequence Sum

### `solution.py`
Naturally, the first instinct would be to take a dynamic programming approach. The recurrence relation would have states represented by a single integer, where `dp[i]` would be the maximum sum for subsequences ending with `dp[i]`. To compute the value of `dp[i]`, we look back and select the largest value among `dp[i-j]` where `j` is an integer in the range `1` to `k`, after which we add `nums[i]` to that value. The problem with this algorithm is that it is too slow, since each state takes $O(k)$ time to compute, and $k$ is bound by `len(nums)`, which can be a decently large value. If possible, we want to find a method to reduce the time complexity of computing each state to something smaller.  
The main issue is that we linearly walk through each previous state to search for the largest value. If we store these values in a max heap, we can access the largest value in constant time while spending logarithmic time for push/pop operations. Thus this method is faster than $O(k)$, which is exactly what we want. We initialize `heap` to use as our heap, storing the values of previously computed states. We also want to make sure that we only select values that are within range of the current position, which is defined by `k`. As such we push a tuple into the heap, where the first value is the maximum sum of the subsequence and the second value is the index at which the subsequence ends. At each element `i`, we take a look at the heap and check whether its index is within range. If not, we pop it off of the heap until we find one that is. We then compute the maximum subsequence sum for the current position, but only use the sum retrieved earlier if it is positive. Finally, we update the overall maximum sum with the current sum accordingly, and push the current sum with the current index onto the heap.  
Once the entirety of `nums` has been traversed, we simply return the overall maximum sum we had been updating.  

#### Conclusion
The solution as a time complexity of $O(n\log n)$, where $n$ is the length of `nums`. `nums` is iterated over once, and during each iteration push/pop operations could be performed on the heap. As the heap can contain at most $n$ items(if all values are positive, a pop operation will never occur) a push/pop operation will take $O(\log n)$ time - hence the overall time complexity of $O(n\log n)$. The space complexity is $O(n)$, due to `heap` using $O(n)$ memory.  
  

